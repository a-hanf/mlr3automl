% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AutoMLBase.R
\name{AutoMLBase}
\alias{AutoMLBase}
\title{AutoML}
\format{
[R6Class] AutoML

[`R6Class`].
}
\description{
base class for AutoML in mlr3automl. Has subclasses for Classification and Regression.
}
\section{Construction}{

```
AutoMLBase$new(task)
```
}

\section{Internals}{

The AutoML class uses `mlr3pipelines` to create a machine learning pipeline.
This pipeline contains multiple models (decision tree, random forest, XGBoost),
which are wrapped in a GraphLearner. This GraphLearner is wrapped in an
AutoTuner for Hyperparameter Optimization and during training or resampling.
}

\section{Fields}{

* `task` :: `Task` object from `mlr3` \cr
  Contains the data and some meta-features (like the target variable)
* `learner_list` :: `List` of names for `mlr3 Learners` \cr
  Can be used to customize the learners to be tuned over. If no parameter space
  is defined for the selected learner, it will be run with default parameters.
  Might break mlr3automl if the learner is incompatible with the provided task
* `learner_timeout` :: `Integer` \cr
  Budget (in seconds) for a single learner during training of the pipeline
* `preprocessing` :: `Character` \cr
  Type of preprocessing to be used. Possible values are "none", "stability"
  and "full". Alternatively, a `mlr3pipelines::Graph` object can be used
  to specify a custom preprocessing pipeline.
* `resampling` :: `Resampling` object from `mlr3tuning` \cr
  Contains the resampling method to be used for hyper-parameter optimization
* `measure` :: `Measure` object from `mlr_measures` \cr
  Contains the performance measure, for which we optimize during training
* `tuning_terminator` :: `Terminator` object from `bbotk` \cr
  Contains the termination criterion for model tuning
* `tuner` :: `Tuner` object from `mlr3tuning` \cr
  Type of tuning. We use Hyperband.
}

\section{Methods}{

* `train()` \cr
  Trains the AutoML system.
* `predict(data = NULL, row_ids = NULL)` \cr
  `data.frame | data.table | Task -> PredictionClassif or PredictionRegr`
  Returns a Prediction object for the given data based on the trained model.
  If data is NULL, defaults to the task used for training
  `resample()`
  `double(1) -> ResampleResult`
  Performs nested resampling with a train/test split as the outer resampling
}

\examples{
"add later"
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{AutoMLBase$new()}}
\item \href{#method-train}{\code{AutoMLBase$train()}}
\item \href{#method-predict}{\code{AutoMLBase$predict()}}
\item \href{#method-resample}{\code{AutoMLBase$resample()}}
\item \href{#method-tuned_params}{\code{AutoMLBase$tuned_params()}}
\item \href{#method-clone}{\code{AutoMLBase$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new AutoMLBase object
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$new(
  task,
  learner_list = NULL,
  learner_timeout = NULL,
  resampling = NULL,
  measure = NULL,
  terminator = NULL,
  preprocessing = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{task}}{* `task` :: `Task` object from `mlr3` \cr
Contains the task to be solved.}

\item{\code{learner_list}}{* `learner_list` :: `List` of names for `mlr3 Learners` \cr
Can be used to customize the learners to be tuned over. If no parameter space
is defined for the selected learner, it will be run with default parameters.
Default learners for classification: `c("classif.ranger", "classif.xgboost", "classif.liblinear")`,
default learners for regression: `c("regr.ranger", "regr.xgboost", "regr.svm", "regr.liblinear", "regr.cv_glmnet")`.
Might break mlr3automl if the learner is incompatible with the provided task.}

\item{\code{learner_timeout}}{* `learner_timeout` :: `Integer` \cr
Budget (in seconds) for a single learner during training of the pipeline.
If this budget is exceeded, the learner is replaced with the fallback
learner (`lrn("classif.featureless")` or `lrn("regr.featureless")`).}

\item{\code{resampling}}{* `resampling` :: `Resampling` object from `mlr3tuning` \cr
Contains the resampling method to be used for hyper-parameter optimization.
Defaults to `rsmp("holdout")`.}

\item{\code{measure}}{* `measure` :: `Measure` object from `mlr_measures` \cr
Contains the performance measure, for which we optimize during training.
Defaults to `msr("classif.acc")` for classification and `msr("regr.rmse")`
for regression.}

\item{\code{terminator}}{* `terminator` :: `Terminator` object from `mlr3tuning` \cr
Contains the termination criterion for model tuning. Note that the Hyperband
tuner might stop training before the budget is exhausted.
Defaults to `trm("none")`}

\item{\code{preprocessing}}{* `preprocessing` :: `Character` \cr
Type of preprocessing to be used. Possible values are "none", "stability"
and "full". Alternatively, a `mlr3pipelines::Graph` object can be used
to specify a custom preprocessing pipeline.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-train"></a>}}
\if{latex}{\out{\hypertarget{method-train}{}}}
\subsection{Method \code{train()}}{
Train AutoML learner. Calls the `train` method of the associated `AutoTuner`
with the training instances in the given task.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$train(row_ids = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{row_ids}}{IDs of observations to be used for training. If no `row_ids` are provided,
trains on the entire data set.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict"></a>}}
\if{latex}{\out{\hypertarget{method-predict}{}}}
\subsection{Method \code{predict()}}{
Make predictions for new observations
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$predict(data = NULL, row_ids = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{Optional. If provided, predictions are made on this dataset. Needs to have
the same format as data used for training.}

\item{\code{row_ids}}{IDs of observations to be used for predictions If no `row_ids` are provided,
predictions are made for the entire dataset.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-resample"></a>}}
\if{latex}{\out{\hypertarget{method-resample}{}}}
\subsection{Method \code{resample()}}{
Convenience function for resampling with an AutoML Object. Performs nested
resampling with `$resampling` as inner resampling and `rsmp("holdout")`
as outer resampling.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$resample()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-tuned_params"></a>}}
\if{latex}{\out{\hypertarget{method-tuned_params}{}}}
\subsection{Method \code{tuned_params()}}{
Convenience function for trained AutoML objects. Extracts the best
performing hyperparameters.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$tuned_params()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{AutoMLBase$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
